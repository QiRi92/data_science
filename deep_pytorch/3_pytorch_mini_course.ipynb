{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580cfa1a-6f3d-4a0c-adae-43981ef9d5db",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b4c74a-23f3-4289-807f-355e7776a7ba",
   "metadata": {},
   "source": [
    "Deep learning is a fascinating field of study and the techniques are achieving world class results in a range of challenging machine learning problems. It can be hard to get started in deep learning.\n",
    "Which library should you use and which techniques should you focus on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e34280-0e47-4abf-bbae-d4af6cbebab5",
   "metadata": {},
   "source": [
    "## Mini-Course Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22410316-9267-44bb-a0eb-b1f00eee47ba",
   "metadata": {},
   "source": [
    "This mini-course is divided into 9 parts.\n",
    "\n",
    "The topics you will cover over the next 9 lessons are as follows:\n",
    "\n",
    "**- Lesson 1**: Introduction to PyTorch.\n",
    "**- Lesson 2**: Build Your First Multilayer Perceptron Model\n",
    "**- Lesson 3**: Training a PyTorch Model\n",
    "**- Lesson 4**: Using a PyTorch Model for Inference\n",
    "**- Lesson 5**: Loading Data from Torchvision\n",
    "**- Lesson 6**: Using PyTorch DataLoader\n",
    "**- Lesson 7**: Convolutional Neural Network\n",
    "**- Lesson 8**: Train an Image Classifier\n",
    "**- Lesson 9**: Train with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058ffd19-3b75-41bd-9b8a-b2696d3505b2",
   "metadata": {},
   "source": [
    "## Lesson 01: Introduction to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b460d64c-cbf2-479e-bcc5-affd889f3e57",
   "metadata": {},
   "source": [
    "PyTorch is a Python library for deep learning computing created and released by Facebook. It has its root from an earlier library Torch 7 but completely rewritten.\n",
    "\n",
    "It is one of the two most popular deep learning libraries. PyTorch is a complete library that has the capability to train a deep learning model as well as run a model in inference mode, and supports using GPU for faster training and inference. It is a platform that we cannot ignore.\n",
    "\n",
    "In this lesson your goal is to install PyTorch become familiar with the syntax of the symbolic expressions used in PyTorch programs.\n",
    "For example, you can install PyTorch using <code>pip</code>. The latest version of PyTorch at the time of writing is 2.0. There are PyTorch prebuilt for each platform, including Windows, Linux, and macOS. With a working Python environment, <code>pip</code> should take care of that for you to provide you the latest version in your platform.\n",
    "\n",
    "Besides PyTorch, there is also the <code>torchvision</code> library that is commonly used together with PyTorch. It provides a lot of useful functions to help computer vision projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe7b6e-065a-42a8-bdc1-4ef20eaca90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d807b7-ac2d-4896-911e-a24e58a7d2cd",
   "metadata": {},
   "source": [
    "A small example of a PyTorch program that you can use as a starting point is listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b31f56-dc53-48ca-af17-78d1da736eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "# Example of PyTorch library\n",
    "import torch\n",
    "# declare two symbolic floating-point scalars\n",
    "a = torch.tensor(1.5)\n",
    "b = torch.tensor(2.5)\n",
    "# create a simple symbolic expression using the add function\n",
    "c = torch.add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b574bd-cd84-42dc-a2cf-a73aabc53ad9",
   "metadata": {},
   "source": [
    "Learn more about PyTorch on the [PyTorch homepage](https://www.pytorch.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe32481-2030-4b81-b8e9-50447d489ad2",
   "metadata": {},
   "source": [
    "## Lesson 02: Build Your First Multilayer Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3614753c-0d26-4575-9108-f04e687e00fc",
   "metadata": {},
   "source": [
    "Deep learning is about building large scale neural networks. The simplest form of neural network is called multilayer perceptron model. The building block for neural networks are artificial neurons or perceptrons. These are simple computational units that have weighted input signals and produce an output signal using an activation function.\n",
    "\n",
    "Perceptrons are arranged into networks. A row of perceptrons is called a layer and one network can have multiple layers. The architecture of the perceptrons in the network is often called the network topology. Once configured, the neural network needs to be trained on your dataset. The classical and still preferred training algorithm for neural networks is called stochastic gradient descent."
   ]
  },
  {
   "attachments": {
    "6b549645-610e-4233-89f2-949c5c8fd413.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAANwAAAFWCAYAAAACBvOLAAAfaElEQVR4Ae2dP6/rSlfGZ+fk3OjUEfS7okCAtBGiviUd0hUf4K1o0e3ebvMBaE6F3i4dHwC6XfKWRzRIu740FLukOAgJwn0maznLk7HjJPZ42fNEiuzY45k1P6/Ha/44dgjr/+w/f/78m83m09cQwgHLH758+SmEsFt/1VlDEihIYLPZ/Lzdbr+HEI74Pj09/aLrIYT37Xb74wPmvIQQ3h44fuihL5vt9tvQxExHAjMR2LyKuN6TiLazQnxAdAfJf+r6lSpn6now/xUTQPQ5SmTINh1FaBr1smmu8CklhFLlXKkud5NAN4HopNeil/TrjujjIStJf+g47qDp5Lh3iXAHREwcj6WsQ/AHNGEhetnWiFrL+TXNc1KFPY7rKke3o/8Zy9puv2kZIcSIjuP5IYHiBD5CCPhe+8RICCdHQnHoRoDJwegHxnRdgpM+HfqG6De+iQjQz2uOteVkhA0BNmnTcozgTJ5RaPEC0xfRk7rwJwmMSkCbk9cyRdSBgyNaDRacZBqdPCkgCkGEYnfFtCowFbb+NglbgusoR9JEoZlDmz4rLiL8kEBRAhDR0BFE7ceNJrgQQtq0awlpDMFJNEO++sHFo2m26kYuSaAEgaERDsJo0qoQTNPN2to09WRjV4SL0dIeKOsfIpJG2HdGOGSnZcfojIiayStjAjeRwAQEMJAg/ajeK744aSOkkQSXjawyB9hqumZE0oqEgkbFZUntZKoDAzzNPKM0jdPoao/jOgmMT0D6UF2DH7bA6MzivE3kyUQ47eshvX5yQngTYWkaXerxUYwq7AcEp/liuZN8oj2Z/qNNy3USmITAs1z5MVJp+zlNYSKypjmJHRrxZBi/SavbdZRSdqjgbBSNgyZpmU1ZMn2ggkuFrek6yonFIg1ELWkbG6X/dkvf1R7LdRJ4jIBx3g8ZnsfoHYSI27lULKkgY5NOohTSx+ghv5umJyxLoqiODKrg0HSMQpfydJpCm3vadNR02kT8kAsF7NNPtFXqg3L2kkaPRbqd1PGYXiw0Ey5JYHICcHYZqIBY0i/EcRH9xGGTtJtXEV0jBBP1kDb2zWRkFL9VeDEfI2BT52YYvykLZaflmAtHE42xLem7aR6wz0ZcUx5XSaAcgRc03+DQ4sAXQktMeUZ6afJp2hgh03Ti/HoTtAotNk9xvJTXJYLB5SAvEbmasEfeGTt1P5cksHoCjeBWX1NWkAQcEKDgHJwEmlAPAQqunnPNmpIACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZAACZCAPwJdL2D0ZyktIoGlE5A3py69GrSfBBZBYB9C+OC7thdxrmjk0gnIe7iP8m7vpVeH9pOAdwKb1xDCcbPdfvNuKe0jgcUTEKEdt9vt9xDC8+IrxAqQgGcCIrQouM3m01fPttI2ElgDgSOalPLl4Mkazijr4J4ABMcPCZBAIQIUXCHQLIYEQICCox+QQEECFFxB2CyKBCg4+gAJFCRAwRWEzaJIgIKjD5BAQQIUXEHYLIoEKDj6AAmUIvD09PQL76MsRZvlVE+AgqveBQigJAEKriRtllU9AQquehcggJIEKLiStFlW9QQouOpdgABKEqDgStJmWdUToOCqdwECKEmAgitJm2VVT0AeJPRSPQgCIIFCBN7k+ZSFimMxJFA3AQqu7vPP2hcmQMEVBs7i6iZAwdV9/ln7wgQouMLAWVzdBCi4us8/a1+YAAVXGDiLq5sABVf3+WftCxOg4AoDZ3F1EzjwtcN1OwBrX5YABVeWN0urnAAFV7kDsPplCVBwZXmztMoJUHCVOwCrX5YABVeWN0urnAAFV7kDsPplCVBwZXmztMoJUHCVOwCrX5DAZvPp62az+blgkSyKBGomsHkNAV9+SIAEChCg4ApAZhEkoAQoOCXBJQkUIEDBFYDMIkhACVBwSoJLEihAgIIrAJlFkIASoOCUBJckUIAABVcAMosgASVAwSkJLklgcgLyeIXD5AWxABIggRAoOHoBCRQkQMEVhM2iSICCow+QQEECFFxB2CyKBCg4+gAJFCRAwRWEzaJIgIKjD5BAQQIUXEHYLIoEfvjy5acQwhtJkAAJFCCw3W5/pOAKgGYRJAACFBz9gAQKEqDgCsJmUSRAwdEHSKAgAQquIGwWRQIUHH2ABAoSoOAKwmZRJEDB0QdIoCABCq4gbBZFAiGE56enp19IggRIoAwBCq4MZ5ZCApEABUdHIIGCBCi4grBZFAlQcPQBEihIgIIrCJtFkQAFRx8ggYIEKLiCsFkUCVBw9AESGJnAMx6lgOeX/MnLX/zuj/74z/4V3z/987/8n/0f/OF/b7fb71jiN7YjDb44Ru5E2Y9sD7MjgVUR2EEoEA+EpGL6q7/+m//927/77RHfv/+Hfzz+7p/+5f/++ff/ftQvfmO7pkF6iFAFCRGGEF5WRYqVIYE7CewQkSAyCARCgXAgpn/7j/96+AsxIj8VMMqRBxDt7rSXh5HAIgnsrcgQocYSWZdQkT/Ep9FPIh+bnYt0Hxo9lMAejo5oBuf//ft/PhzFugTWtx3iQ9MTdojwGPGGnkGmWwSBHRwbTTs4+tTRrE9sdp8KD3bJw2UpvEW4E43sJABH9iY0Kzqso6+Hpib+8iN9vM76cAcJeCWw0xFHOHTq5B5/w05cHKSZ6ZUr7SKBCwJ7RAw0H+fqp90raDQzYTsuFiEENjEvTi03eCPwgiiBQZF7nd7DcbhYyL/Kn70Bpj0kEAmg/wOxYZjfg2getQH1QH3kzpWiZ3mz+fQV708YqU+Ji0YTrTebzc8F3s3QVSanYsbwJB2FXEp/bagYUR9MH4zk+ENRw1mP+G62229DD8qlg92wH8+BMfsPkr/ZNN6qsProKNPaMV6hNeWkI5FehvuHimloOtQLTlsu0m1eo9hOUQ7Ce+DWtFNeifMjykzo+L1lNpG2Jo2MWdfYZ1ur2FSUOoI5raPG07JD31Eim0Y6RKS+z14uBhBm4tBZ5+/La8i+WJ6UmWki3lzms+Q15CKgdR2SdkhdFpXmGX2ctTUjVWTpEgNBMpCSOPV450yaY0fpZyHjN2kSZhw7ikubh7EJGkL4kEn8eKw2TbEU27FdjwmZ8prKSD5HSYPtEDRehKll6RLb1L7W/kyZVigvcmHRfLQJbSN6vOgID7Vb09tyG7vXurIDrKWPRqaiuvYbo5cyZTDVeVWnig6sTm8EaMsV544R5QVRQh3YRLyYn4hGHVnLQF64eHzIcTZvrCN/9MWQBvZg/UPy0qgU85JBHhyDMvrKVMHBXvQt9QIR/46F37JdbY2Ck7LjIJLULS03tX1dv+F0cL5rDrrG/Zinm2hyHE6NqzccXT/42xIc8103YClOdwwhis3uUgeFQwbZjzzV0bExOutpfwgiljRNzEeFJCJTceihWEbBtm3ONim1TLVDLhYX/VMIzTKIdmRaFlpui4s1bDXrcDY43VyT2ih3zqkH9FfRlDZNrVHOrUQx24TTfKOzisjiNiMSjQSaFktt3g0SnESlRLyNaHL5a1lweuxH5DMXieZYFRfStwSHi0hHVEVaFSPyj4KT47VcXb6ZJqtuW91yB2ebc5BERw0zfQlcGR/+Dmkmo9+aueo+erJxtdZ+DJxOv3F74nTqwHDKnk+v8zfHifPbaPGeEcReIqY6umV9i+D6RASbtG5I15dW7WjqsboVRLe5m5IaYeZuriLKmwGKR891bEqJiFVodokoAgfX6KVOOY7gTpPhmP74USNe0m+E42v/6g3C076csVkY9Ioc+WjTGXXIfbRu1QtuP3d0g8i8CM5MFVxx+pxPtbdpE9E2G5MUMjcX7xKxTcWLJt8pr+j0Nh2cVz/q0PobSwy3f8ex+Eq/UcWN/fGYnH2S9pYIh/xwAbERtbEFkVXyxDbYjQtNTpzrjnAYKBnS3Jo68ngRHOqJaJ9EgsZxbliJAyNX+iPR8UwzNkbEjCMmDtobbVITD8hfykgdHIKyETYeq6OobdubMu3FQEWuws8KWARtBZbUp2XyqgWHYeDvcw2UWBF7EhxsyUSDlldc+6FOmxlxTA+NTm8Ga9SJD8gDwofjiz3RsXUgBv1BiaLIU49r5W+c/WLgxuaDdPiaSPhhBaf1QaTKlKmCw1KaqNo83byK7Yh+Np0VoLV5vYLzEt0gPDTl0H+yIpxzHVHuwWmCGFmMk1mnatYhNDi2ceIdRCrODqfEF6K0kQXNQp08hyPHaQArkKaAEOLcqgyWpM3kWJY0BZOyGhtUJDjWlrmDzVKmpkGxWD+IyPTChYtBK01SZ2NuvHCYpqzdtex1N9HNo+AQ9cVpUictedZLlj1FWVPkWZL/eGV5GJm0EcxbhINtiLimqTcefOZUHwE405wTzVZsHiMcbMJg0sS3fNXneJXWOI6geRgsUeF5jHA6kFOpj7DaYxFAM8nTAIVGuLkn31X8dok5ymTAYqzTwHxqIYBmkqfmJBwc9ngUHJqVD45W1uJWrGcHgdicRHPJXsnnXvcqODR1O4bbO/ByMwkYAh6bk54jHGyTZqW9JcoQ5SoJ9BDwNh2gkdVrhIN96O/KHRs9ZLmLBDIEIDgP906q0HTpWXDoW8qtTRmi3EQCPQQ8DphAdLgIeLwQqG0cOOlxKu7qJkDB3f5SSI5UdvsT91whgP4IRt60Kedl6TnCobnLO06uOBZ35wl4+LNpTuSeBYcLVObRBHnA3EoCCYHZ3lKaE5pu8yw43uKVeBB/3kTA1YQ3BXfTuWPiBRJwKTgMvaOvpAL0tGSEW6CXOzLZpVN7Fhz7cI68d2mm4F/Mnv6Wo5HMs+A4Srk0L3dkr9dRSu+CM88ccXQ2aYp7Al7n4TwLjhPf7t3ar4Fe7zTxeiFAkxcXA95L6denXVvm9eZlz4KDbfy3gGu39mscrtS4YutghZelZ8HJ/+HscxX9nmBa5o5AfMOpF6GpHV4Fxzk4d/67PIM8jlR6FRwGTDhCuTwfd2Wxx4ETr4KDXey/uXLfxRmz89iP8xh10Zx08LjzxTkYDb4kEN8b5umOE4+C4x0ml47DLXcSwP+7PP0R1aPg0JzkuwXudDAe1iaAd4N5mh7wJjgnb89pnzT+WjSB2KxEP0WH5udcehMcRif5WIVF+7c/4zHcDceaU2haNl48qOtzL81gCR/+6s9tF21RnAT3MHjiSXBoag94VfCiTzyNn4/Am4co50Vw5s4SRrf5fHLVJbt49bAXwSG6ycvmV33SWbkZCaAvN/eIpQfBYZoEgzchBL6bekZ/rKFoNJ8++ubl0OyEKKb8ztm0RT8WYuP/3mpwdwd1xAQvHM7DAMoco5SngZJwcHAqaEItBDw0LecQGyKrPFmZTclanN1JPeFw716fDzmFGFFX6bdxVNKJE9ZkBgSHfzb39uemcPw58jRTAC81nWTW1RkB+f/XqkWnYuPNyc6cr1ZzZC5qlaJTsfFuklq921m9NcLJ1X9VotO5Nhn+/2CEc+Z8tZkDseFfzk9PT7+g7viN9TUMpGA0UgZIYp9N6qjPLOEIZW3OPnd9VWwyuf1m7MFAyjvmqpY4Tweb4y1b2+23EIIdjUQd31FfmRaw+0z1uUoC4xOI/48730myeU2K2GGeDlGh746UOUYb+8qErfjn9q+jr5jUbkUx9FNFaHoHzUciyAQBf5LAiATggPLQHDhgdqhc+3Xeox0GRmAjmpBdNyOjLriASJ0htmydR0TMrEigRQBNrIM4YGtH8mOPaIf5OvSLPDUzYcu5rxajdCuqpfVAXWOk23z6KnVKkvAnCUxAAFd7c3vT0Cs9+nZviCJwckSVvubdlPtUaCcBxYvB0P6YPsIc6RnlJvAtZnlJ4FFne0Z0gLOjGYd+U4mohzIweooyUbY8g0QFdFnLK1swVSAXnSspuZsEHiAAsYzUnNrrQISKD4IYM/IhL+QpT0T+DoFIH+1uoVl0yI9/0bFEuD42gReZjxraBBta/h6Oi6iDJie+iERoekIwiIIQTxoJ8RvbsR/p8MUxOFZFhjxl8KavfzbUzjTdVDzScvi7QgK7glf0Z4gE76eDYFAuRIhIeJ6KOP3BFdshLqTDF8dAvHIHzBQia536ESN+K1/+qJyANMXsBPesRERQs9oghT/ap/VQB9rgjAD6PBiVG6XvM0Ld1MlHyOrxLKQfN9vFCOVLszlXmech+289t6YVkSuzb9uL8Jq89dFnhPd9B2d3y+NOkM4J9xlglmxu56r3Ls3tnBNHVl37ZQDsHpY45o7HTMT5Thx79eKNVsxIA3Q5Zj63SdMN9xDmTuYcRpvbyi5uKZvDHi0T85Gz3O51RTQfeuN1RxTEuYXdt34OEqluPG644MTu2VoON1ZslOQ7uZ3px1FyGyETOJcZPIGzePoc5rgii5CO0s+2PHAR0O36Twe7H03zOyOVzeaWdQquh1aEc0ezoSfLx3aZ6Bb0BYiP5Tju0dq3HHr3zVilZ4UjAoSgsP9NIkZTpgo1jVTy+w2jwzhO8klbOLkIh3of9DjkLy0k+BBsCNI1gU0vsh7LkQuVNjORVm8bRPQ9mOi8t8fBvrX0CXWgREA158nDynPqPB6Mgg3qrKXtgZNnmKhoghGfOnUwTVF7jmOfD/nJfjTpIBAsrehakVHFK81T5KHHxb80nftsTYTTpmyTVuxHGbDnTVoyEJwVlfZXY2tCxJ2L3qVPwcPlaSUfzmiCDNwKDk4JJzBX5Amqn8uycWQVFBz3aAa7bPMyZhBFdYpi8bdcLC6cV7ebvJDeCg5lQRgQUSNeiW5Ih6/Y1djZErCK33ITASJd/KioxR7djKWKuynb7nS/jgrJlcNe0TzZ7Vlw4KR3oBTjp86tDqvOKdv13MVoIT/gnFaQ2KxRJWf3exJBG8FpWRkhxDxzgkvsik8LSO3pEpyI09qIutjfWt9FLGE8TkzpfsgtcLwLDnUpPZWyQxNMnDGWn5kK0H7RTkViHR/p5Rg089IvfAIiU8duBCeRD78zPtNEtDTCaSSO510vGDaKpoKTsmMTVezU/mUrr1scyUPaWUbabqw4AAO8549euEo6Q9Nnyzir9i8x2BTntzKChGg0CqKZlvuiXvg0gtPm4LnZKCniYlTBIcfmpnexAXaoLXoxsAb4XceJkBPl2nC5GjZte69EpYlVzE4zMBL7a5kmHsQSpwmky5Da9iHbhyBVJ28GZOS8tI69FGMqwFNyObbVxM1dNFqZh7BHpBabj5n6Jsl9/YTI3qWp4cuyxJqlCE6bQAWZRqFJcxCCyEVXtAwgNJ2fs3Tj9sxxcSBIjtP0jeCkKWl/a5o4jysRSGy5X3ByQYH9rXrlxKoGuF1KZdIrnkt7FyS45tGBpu8zNdMPaSp2NLk3r7L/QpBnx43NdXVqXIjRn2tFHxERtuvHpsGxEL8K2JQ1XHDSbdDxBLwMFDdgIC/kq03bxj7Zr/a4XgIQKqaQXRu7JMEJyJIDKNHxzeBJ61yq00pzrbUPP9AsM4JU8Wr0sl0N3aZ5QAAiuigKFYaKTnxruOBMc7SZqrDbpA4oJ70YqE1ulzra49ZAa9gCBQdnLHVB00igEcCiwzpGMxEpMiOKTdLYN8KIobR8LtJKHrkLNO4GQv66T0WoYlX79LcWmh4XtyMv6ZtZG+I/IGCf7NOyNC+/S+lfoPmRAnBrtNiME7mYz5Ka7HdAfcHARaavCp9K5+/uyH49h7i7OXkIWrmqLUpwMwygDEE5VhoICxFc37+AiIOIFKObXGzGKmu5+Uh7eGmOq/NJi7MbzaMlTLvc6dEQGFpK0qc63VxOsZ1pAhCuSl1t/XNKZ2sLjXBKseQAipZZcql9NPjXYropkwNCm1scd/Kyxi5g4YIrOYAyNnrmdw8BcdhFzLnl6odmStewdy69t20rH0Dxhnt2e1ZwhcVcTpzPmR3mnQbE0bvMqN6d2fEwzwRW0IdYvODmuAPFs0+u07b1jJItX3DiYSu4+K1TK2PUKjZj5C6AMfKbMY/VCA7zVaXuQJnxfFVZdOzzLG7uKn+qViM4/WvLYgew8ueHW9d2Jc09MWqpZ5kDKEs9cz12L+rm5J566K41CY4DKHpW17DEnJv8I3ZNs/6rEpz4GQdQViC4vdy7h9ts1vRZo+DW1uxfk78NqwvuxljyHRk9tVyj4DiA0nPCl7BrsTcnD4CL5ye6ed/BAHuHJlnR1M3QKq8j3UxP/y0Gb62C0weiLuoPwcXOuteCKrg5drWCE596W/i9ol6lMYldNXS+1y64Gs7hJM4/R6Y1XB3XLjgOoMyhnFvLXOIDgW6tI9LLvOLapjpSFBxASYk4+73IBwLdw1DmFtHsWvVHRmI5gOLzLK/p5uR+wrUITiis7ba8/pO7kL1rnnO7OAWVCY4DKBceMP8Gz28rHZ1OZYLT92Kv5K9Vo7tD2QzNzcllC56xtPoEFx83h3dbr/Humhk96fai9YFAax+xS8ngYaNVfTiA4uN0L+FtpVOQqk5wApEDKFN405A8ccWTptWa/uc2pOpIU6vgOIAy1ENGThcnRSt+rmGtguMAyshCGphdnHOr+cEzFQsuVHODw0AxTJ6s9maFDhRNDtprAbXcwueFf+0d52fpu3o5H3PZUbsfTM+dV7bImII7uZq2dBDx+ZmAwFofCHQrKgquIVbP/bNNlUutLPVtpRPwoeDOUDmAcmYx6lpVNydfIQcW+MsKPyEEdjPGd4P4QCB5ieL4uS8sR7nFqeYpkdwZ4wBKjso92yp4INBNWCi4LC4OoGSx3L5R55wAlJ8Q9DFyjHAX3sABlAskd2zg8+YTaIxwCZDzzziKLXzOW7k2jADAVXxzcickCq4TDQdQutFc3cMnNnUgksEj/vu5g08IgQMo3Wy69rA93kWGgusi02znAEqDYtiKAuNASYYXBZeBcrGJF+wLJD0b2CTogUPB9cA57UJ3JN6BEkKo7dEbV+G0EsCZVvi20lYdH/1BwQ0jiDtQ6Ev9rHTOjVelHk6nGwFik6knFXcJgaoen3jrWa/1gUA3coLYKLiB0HgPbgeoF5lz43+bOgCdN1NwZxbX1/gvk0tGtT8Q6JJI7xYKrhfP5U52VSwT3pxsaQxZp+CGULJpOBh3psE5tzOLQWtoIslFalB6JmoIcAAFt+FwAKBxiKErB5kaGJqe6U4E6h5A4T9179YBBXcnupoHUPgsijudJoRAwd3Prs4HUdV8pbnfV5ojKbgGxe0rZgDl9oMXekTdbenHTxoF9zjDegZQcH8bO/0Pecwb/9X8ED8cXMdFv8Zw/rBrXGZAwV0yuXnLaXrl09ebD1zQAZzxH+dkUXDjcFy9P/KBQOM4CgU3Dsew2hYXHwg0koecsqHgRsS5xjEF3pw8ooPIY875+InxmL6s7Fa5+N8tPrh0JAeRvzFRcCPxXF02MslNBxnpzFJwI4FkNiQwhAAFN4QS05DASAQouJFAMhsSGEjgI4TAR1EMhMVkJPAogeOjGfB4EiCB4QQouOGsmJIEHiZAwT2MkBmQwHACFNxwVkxJAo8RkHnNxzLh0SRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiRAAiSwAAIveG2Us1fV4o06LwtgRxNJ4DYC2+32xxDCMYT4OuXbDp4mNcT24cieaWrJXOsk4FBweKWzpwtAnY7BWk9DoENwiDL6LvP9D1++/IRv5uWJO0mH5c6k02Ot0diWe/milhXzUHvM+9SxXT/PV8rQdFySgE8C6uBJE+6g/brtdvv9FHEQdcLR9vX0WNmGt5nGNKd0n75ChFpreb3wm/42y4Mc9/z58+ff2Dx0u+SDY5v8ZR3bciI22XOVBBwRUNGkghOhfYgInpFORAOnjxHsfCyE2AhsJ+utZuEQwUFYmmc7wsX+5VFsgcD2Yq+W64goTSGBHgLq4KngEEHEwZujJZI128/HhjRy7Tbb7bfT4Mcpyg0UHMqCmFtiDSG8yQWgiZgnozavqY2NsVwhAY8EzqJpjVI2zTxrs6ZVJ9fftpl5Tn+KSjq8/5jgTnlBxFJWro94LpprJOCVgIomF+FSmzVtKjjZ3kouaY4y2BIeE1wwzdRTPw75SbOTfbgWef5wTUBFNLbgtPmpYnxQcMowjpj+2uyMgzoycPJuB2c0IZck4JLAGILLNymDNktjBIoR6dSvSzno6KM2Ey/6cLBRI6U5GP05LYN3pRgwXHVMYAzBSfSyAxoY1cR0QjOYgv6XbLNNQE3XjHzmBk3MAIw9FlRVcCpWx6RpGgmEEMYQHIR06lNtfpam6YeIq4k82sQ8iXPzKv0vzN2lEQ6iOhrBvkh0O56PRTmN2CA6fkhgMQQgijcdCIHVIo4mOpmaxLQi0kasSG8EBBFBBBdRR/J9h5gQtSAkyQtlNdELtkhUQ1rc66llIV0UM/ZLfjayGlO5SgIrI6DR0Yp1ZVVkdUjADwEKzs+5oCUVEKDgKjjJrKIrAs8ySNIMjriyjsYsmsD/A7D0y5QtvFTjAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "d0a4422e-f373-4c9e-aadc-c7876a63f84f",
   "metadata": {},
   "source": [
    "![image.png](attachment:6b549645-610e-4233-89f2-949c5c8fd413.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c64f8d-ed1c-43d5-b02b-1f16239aed68",
   "metadata": {},
   "source": [
    "PyTorch allows you to develop and evaluate deep learning models in very few lines of code.\n",
    "\n",
    "In the following, your goal is to develop your first neural network using PyTorch. Use a standard binary (two-class) classification dataset from the UCI Machine Learning Repository, like the [Pima Indians dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv).\n",
    "\n",
    "To keep things simple, the network model is just a few layers of **fully-connected** perceptrons. In this particular model, the dataset has 12 inputs or **predictors** and the output is a single value of 0 or 1. Therefore, the network model should have 12 inputs (at the first layer) and 1 output (at the last layer). Your first model would be built as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3149e89-2889-4a9d-bdbf-3c81ab2765ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "  nn.Linear(8, 12),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(12, 8),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(8, 1),\n",
    "  nn.Sigmoid()\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b7af2a-dd7a-418d-a6eb-f47a2b67f8dd",
   "metadata": {},
   "source": [
    "This is a network with 3 fully-connected layers. Each layer is created in PyTorch using the <code>nn.Linear(x, y)</code> syntax which the first argument is the number of input to the layer and the second is the number of output. Between each layer, a rectified linear activation is used, but at the output, sigmoid activation is applied such that the output value is between 0 and 1. This is a typical network. A deep learning model is to have a lot of such layers in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc53645a-0e8f-45aa-8162-8984bc620ce5",
   "metadata": {},
   "source": [
    "## Lesson 03: Training a PyTorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c27b81-29f1-44b6-9cfc-b2136b15afd0",
   "metadata": {},
   "source": [
    "Building a neural network in PyTorch does not tell how you should train the model for a particular job. In fact, there are many variations in this aspect as described by the **hyperparameters**. In PyTorch, or all deep learning models in general, you need to decide the following on how to train a model:\n",
    "\n",
    "- What is the dataset, specifically how the input and target looks like\n",
    "\n",
    "- What is the loss function to evaluate the goodness of fit of the model to the data\n",
    "\n",
    "- What is the optimization algorithm to train the model, and the parameters to the optimization algorithm such as learning rate and number of\n",
    "iterations to train\n",
    "\n",
    "In the previous lesson, the Pima Indian dataset is used and all the input are numbers. This would be the simplest case as you are not required to do any preprocessing of the data since neural networks can readily handle numbers.\n",
    "\n",
    "Since it is a binary classification problem, the loss function should be binary cross entropy. It means that the target of the model output is 0 or 1 for the classification result. But in reality the model may output anything in between. The closer it is to the target value, the better (i.e., lower **loss**).\n",
    "\n",
    "Gradient descent is the algorithm to optimize neural networks. There are many variations of gradient descent and Adam is one of the most used.\n",
    "\n",
    "Implementing all the above, together with the model built in the previous lesson, the following is the code of the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd806961-4951-441a-80ac-16238ed20598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, latest loss 0.5938032269477844\n",
      "Finished epoch 1, latest loss 0.5658130645751953\n",
      "Finished epoch 2, latest loss 0.5529212355613708\n",
      "Finished epoch 3, latest loss 0.5407994985580444\n",
      "Finished epoch 4, latest loss 0.5310658812522888\n",
      "Finished epoch 5, latest loss 0.5164268016815186\n",
      "Finished epoch 6, latest loss 0.5074374675750732\n",
      "Finished epoch 7, latest loss 0.5025941133499146\n",
      "Finished epoch 8, latest loss 0.4991707503795624\n",
      "Finished epoch 9, latest loss 0.4926738440990448\n",
      "Finished epoch 10, latest loss 0.489146888256073\n",
      "Finished epoch 11, latest loss 0.48124074935913086\n",
      "Finished epoch 12, latest loss 0.4745546579360962\n",
      "Finished epoch 13, latest loss 0.4680787920951843\n",
      "Finished epoch 14, latest loss 0.46532484889030457\n",
      "Finished epoch 15, latest loss 0.4635985493659973\n",
      "Finished epoch 16, latest loss 0.45680731534957886\n",
      "Finished epoch 17, latest loss 0.4499308466911316\n",
      "Finished epoch 18, latest loss 0.4441033601760864\n",
      "Finished epoch 19, latest loss 0.4373527765274048\n",
      "Finished epoch 20, latest loss 0.43272772431373596\n",
      "Finished epoch 21, latest loss 0.4289874732494354\n",
      "Finished epoch 22, latest loss 0.42281368374824524\n",
      "Finished epoch 23, latest loss 0.4189644455909729\n",
      "Finished epoch 24, latest loss 0.41636911034584045\n",
      "Finished epoch 25, latest loss 0.4189683794975281\n",
      "Finished epoch 26, latest loss 0.4147760272026062\n",
      "Finished epoch 27, latest loss 0.41703853011131287\n",
      "Finished epoch 28, latest loss 0.40800055861473083\n",
      "Finished epoch 29, latest loss 0.4028908312320709\n",
      "Finished epoch 30, latest loss 0.40020638704299927\n",
      "Finished epoch 31, latest loss 0.3988492786884308\n",
      "Finished epoch 32, latest loss 0.39972108602523804\n",
      "Finished epoch 33, latest loss 0.4033943712711334\n",
      "Finished epoch 34, latest loss 0.4025445580482483\n",
      "Finished epoch 35, latest loss 0.4033436179161072\n",
      "Finished epoch 36, latest loss 0.39650243520736694\n",
      "Finished epoch 37, latest loss 0.3976343870162964\n",
      "Finished epoch 38, latest loss 0.3971866965293884\n",
      "Finished epoch 39, latest loss 0.4033258259296417\n",
      "Finished epoch 40, latest loss 0.39354270696640015\n",
      "Finished epoch 41, latest loss 0.39759036898612976\n",
      "Finished epoch 42, latest loss 0.39110273122787476\n",
      "Finished epoch 43, latest loss 0.3954622447490692\n",
      "Finished epoch 44, latest loss 0.39180684089660645\n",
      "Finished epoch 45, latest loss 0.39603307843208313\n",
      "Finished epoch 46, latest loss 0.39949363470077515\n",
      "Finished epoch 47, latest loss 0.39459922909736633\n",
      "Finished epoch 48, latest loss 0.3901551365852356\n",
      "Finished epoch 49, latest loss 0.3882271945476532\n",
      "Finished epoch 50, latest loss 0.3976416289806366\n",
      "Finished epoch 51, latest loss 0.40288856625556946\n",
      "Finished epoch 52, latest loss 0.41058075428009033\n",
      "Finished epoch 53, latest loss 0.4164535105228424\n",
      "Finished epoch 54, latest loss 0.4203798174858093\n",
      "Finished epoch 55, latest loss 0.414970725774765\n",
      "Finished epoch 56, latest loss 0.4113255739212036\n",
      "Finished epoch 57, latest loss 0.4087011218070984\n",
      "Finished epoch 58, latest loss 0.416216641664505\n",
      "Finished epoch 59, latest loss 0.4175747334957123\n",
      "Finished epoch 60, latest loss 0.4219523072242737\n",
      "Finished epoch 61, latest loss 0.4163828194141388\n",
      "Finished epoch 62, latest loss 0.4176848828792572\n",
      "Finished epoch 63, latest loss 0.4135705232620239\n",
      "Finished epoch 64, latest loss 0.4064056873321533\n",
      "Finished epoch 65, latest loss 0.4051419794559479\n",
      "Finished epoch 66, latest loss 0.4045044481754303\n",
      "Finished epoch 67, latest loss 0.40160828828811646\n",
      "Finished epoch 68, latest loss 0.398022323846817\n",
      "Finished epoch 69, latest loss 0.396837443113327\n",
      "Finished epoch 70, latest loss 0.38968074321746826\n",
      "Finished epoch 71, latest loss 0.39726027846336365\n",
      "Finished epoch 72, latest loss 0.3903827667236328\n",
      "Finished epoch 73, latest loss 0.39993178844451904\n",
      "Finished epoch 74, latest loss 0.3982585370540619\n",
      "Finished epoch 75, latest loss 0.3891620635986328\n",
      "Finished epoch 76, latest loss 0.4215547442436218\n",
      "Finished epoch 77, latest loss 0.3815373480319977\n",
      "Finished epoch 78, latest loss 0.3750707805156708\n",
      "Finished epoch 79, latest loss 0.3836689889431\n",
      "Finished epoch 80, latest loss 0.3689464330673218\n",
      "Finished epoch 81, latest loss 0.379139244556427\n",
      "Finished epoch 82, latest loss 0.36340081691741943\n",
      "Finished epoch 83, latest loss 0.37066328525543213\n",
      "Finished epoch 84, latest loss 0.3586794137954712\n",
      "Finished epoch 85, latest loss 0.3642880320549011\n",
      "Finished epoch 86, latest loss 0.3558911979198456\n",
      "Finished epoch 87, latest loss 0.3613189160823822\n",
      "Finished epoch 88, latest loss 0.3547203242778778\n",
      "Finished epoch 89, latest loss 0.3563326299190521\n",
      "Finished epoch 90, latest loss 0.35244113206863403\n",
      "Finished epoch 91, latest loss 0.356078565120697\n",
      "Finished epoch 92, latest loss 0.34690040349960327\n",
      "Finished epoch 93, latest loss 0.34364455938339233\n",
      "Finished epoch 94, latest loss 0.3469041883945465\n",
      "Finished epoch 95, latest loss 0.3414716124534607\n",
      "Finished epoch 96, latest loss 0.336013525724411\n",
      "Finished epoch 97, latest loss 0.338918536901474\n",
      "Finished epoch 98, latest loss 0.3327220380306244\n",
      "Finished epoch 99, latest loss 0.3326190114021301\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "dataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "loss_fn = nn.BCELoss() # binary cross-entropy\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Finished epoch {epoch}, latest loss {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6160f9-855d-47a1-ae82-c5e76b271b1c",
   "metadata": {},
   "source": [
    "The for-loop above is to get a **batch** of data and feed into the model. Then observe the model’s output and calculate the loss function. Based on the loss function, the optimizer will fine-tune the model for one step, so it can match better to the training data. After a number of update steps, the model should be close enough to the training data that it can predict the target at a high accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd4dbe1-56ef-4905-9971-d5c1d9d99f55",
   "metadata": {},
   "source": [
    "## Lesson 04: Using a PyTorch Model for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5bb507-f4f9-443a-8e6b-56ae19f8ad43",
   "metadata": {},
   "source": [
    "A trained neural network model is a model that remembered how the input and target related. Then, this model can predict the target given another input.\n",
    "\n",
    "In PyTorch, a trained model can behave just like a function. Assume you have the model trained in the previous lesson, you can simply use it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192b07bf-4fbe-4754-8987-46cc56e8a450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5.0000, 116.0000,  74.0000,   0.0000,   0.0000,  25.6000,   0.2010,\n",
      "         30.0000]) -> tensor([0.2534], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "X_sample = X[i:i+1]\n",
    "y_pred = model(X_sample)\n",
    "print(f\"{X_sample[0]} -> {y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457955c3-c641-4bd7-9893-bbbefa9fb839",
   "metadata": {},
   "source": [
    "But in fact, the better way of running inference is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb531c2f-5b73-41ac-8b4c-ae349b8391cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  5.0000, 116.0000,  74.0000,   0.0000,   0.0000,  25.6000,   0.2010,\n",
      "         30.0000]) -> tensor([0.2534])\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "X_sample = X[i:i+1]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_sample)\n",
    "print(f\"{X_sample[0]} -> {y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10697142-4970-4b31-bf7d-0357c58af517",
   "metadata": {},
   "source": [
    "Some model will behave differently between training and inference. The line of <code>model.eval()</code> is to signal the model that the intention is to run the model for inference. The line with <code>torch.no_grad()</code>  is to create a context for running the model, such that PyTorch knows calculating the gradient is not required. This can consume less resources.\n",
    "\n",
    "This is also how you can evaluate the model. The model outputs a sigmoid value, which is between 0 and 1. You can interpret the value by rounding off the value to the closest integer (i.e., Boolean label). Comparing how often the prediction after round off match the target, you can assign an accuracy percentage to the model, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504223c2-e177-42d1-8942-a7d2e5217331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.77734375\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9be928-929e-49ed-a006-7b7c653e4212",
   "metadata": {},
   "source": [
    "## Lesson 05: Loading Data from Torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e2d1b-2b03-429d-ac63-c1293badbbad",
   "metadata": {},
   "source": [
    "Torchvision is a sister library to PyTorch. In this library, there are functions specialized for image and computer vision. As you can expect, there are functions to help you read images or adjust the contrast. But probably most important is to provide an easy interface to get some image datasets.\n",
    "\n",
    "In the next lesson, you will build a deep learning model to classify small images. This is a model that allows your computer to see what’s on an image. As you saw in the previous lessons, it is important to have the dataset to train the model. The dataset you’re going to use is CIFAR-10. It is a dataset of 10 different objects. There is a larger dataset called CIFAR-100, too.\n",
    "\n",
    "The CIFAR-10 dataset can be downloaded from the Internet. But if you have torchvision installed, you just need to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327ae8a7-d472-493a-a34e-1accb4f3ff89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "fig, ax = plt.subplots(4, 6, sharex=True, sharey=True, figsize=(12,8))\n",
    "for i in range(0, 24):\n",
    "    row, col = i//6, i%6\n",
    "    ax[row][col].imshow(trainset.data[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7609416-7e2e-4fac-8fd7-ca2b1ee2e65b",
   "metadata": {},
   "source": [
    "The <code>torchvision.datasets.CIFAR10</code> function helps you to download the CIFAR-10 dataset to a local directory. The dataset is divided into training set and test set. Therefore the two lines above is to get both of them. Then you plot the first 24 images from the downloaded dataset. Each image in the dataset is 32×32 pixels picture of one of the following: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, or truck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860ba7a-5da4-4184-a178-69338690ee12",
   "metadata": {},
   "source": [
    "## Lesson 06: Using PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b30c76-b435-41d7-a5ba-340159d0e730",
   "metadata": {},
   "source": [
    "The CIFAR-10 image from the previous lesson is indeed in the format of numpy array. But for consumption by a PyTorch model, it needs to be in PyTorch tensors. It is not difficult to convert a numpy array into PyTorch tensor but in the training loop, you still need to divide the dataset in batches. The PyTorch DataLoader can help you make this process smoother.\n",
    "\n",
    "Back to the CIFAR-10 dataset as loaded in the previous lesson, you can do the following for the identical effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f4dc2-bd48-4ae4-8eb7-59c00708da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 24\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "fig, ax = plt.subplots(4, 6, sharex=True, sharey=True, figsize=(12,8))\n",
    "for images, labels in trainloader:\n",
    "    for i in range(batch_size):\n",
    "        row, col = i//6, i%6\n",
    "        ax[row][col].imshow(images[i].numpy().transpose([1,2,0]))\n",
    "    break  # take only the first batch\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e7682-3d5f-4155-8cea-e53c11ff9001",
   "metadata": {},
   "source": [
    "In this code, <code>trainset</code> is created with transform argument so that the data is converted into PyTorch tensor when it is extracted. This is performed in <code>DataLoader</code> the lines following it. The <code>DataLoader</code> object is a Python iterable, which you can extract the input (which are images) and target (which are integer class labels). In this case, you set the batch size to 24 and iterate for the first batch. Then you show each image in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d992b02-5c5a-4062-b601-5e5c88c08c88",
   "metadata": {},
   "source": [
    "## Lesson 07: Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378b450c-9720-4184-a037-cd2117b9fe47",
   "metadata": {},
   "source": [
    "Images are 2D structures. You can easily convert them into 1D vectors by flattening it and build a neural network model to classify them. But it is known that preserving the 2D structure would be more appropriate because the classification is about what’s in the image, which is **translation invariant**.\n",
    "\n",
    "The standard way for image processing neural network is to use convolutional layers. A neural network that uses convolutional layers is called a convolutional neural network. An example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70b85d0b-5bdd-49c9-ba42-d843c8067c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3, inplace=False)\n",
      "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=8192, out_features=512, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Dropout(p=0.5, inplace=False)\n",
      "  (10): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(3, 32, kernel_size=(3,3), stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(8192, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(512, 10)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0e3efe-fedd-416a-b91f-034195b99ba0",
   "metadata": {},
   "source": [
    "In the above, we used <code>Conv2d</code> layers several times, as well as <code>ReLU</code> activation. The convolutional layers are to learn and extract **features** from image. More convolutional layers you add, the network can learn more high-level features. Eventually, you would use a pooling layer (<code>MaxPool2d</code> above) to group the extracted features, flatten them into a vector, then pass it on to a multilayer perceptron network for final classification. This is the usual structure of an image classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f76c0fd-9aa6-4fe9-b6f9-493edb060351",
   "metadata": {},
   "source": [
    "## Lesson 08: Train an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19fa2a8-3b14-401a-91b9-5f7bb3bd65fd",
   "metadata": {},
   "source": [
    "Together with the DataLoader created for CIFAR-10 dataset, you can train the convolutional neural network in the previous lesson with the following training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e172d-f7b8-4ceb-9772-6d2528a4266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        y_pred = model(inputs)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            y_pred = model(inputs)\n",
    "            acc += (torch.argmax(y_pred, 1) == labels).float().sum()\n",
    "            count += len(labels)\n",
    "    acc /= count\n",
    "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e108b3-3273-4a4d-a9ba-b4e1a4644342",
   "metadata": {},
   "source": [
    "This will take a while to run, and you should see the model produced can achieve no less than 70% accuracy.\n",
    "\n",
    "This model is a multiclass classification network. The output is not one, but many scores, one for each class. We consider the higher score the more confident the model thinks the image belongs to a class. The loss function used is therefore **cross-entropy**, the multiclass version of binary cross-entropy.\n",
    "\n",
    "In the training loop above, you should see quite many elements you learned in the previous lessons. Including switching between training and inference mode in the model, using <code>torch.no_grad()</code> context, and calculation of the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef05974f-85b9-4519-bb2b-83e49e848d0d",
   "metadata": {},
   "source": [
    "## Lesson 09: Train with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c11259f-e6a2-4e2f-8f48-74898d6465c8",
   "metadata": {},
   "source": [
    "The model training you did in the previous lesson should take a while. If you have a supported GPU, you can speed up the training a lot.\n",
    "\n",
    "The way to use GPU in PyTorch is to send the model and data to GPU before execution. Then you have an option to send back the result from GPU, or perform the evaluation in GPU directly.\n",
    "\n",
    "It is not difficult to modify the code from the previous lesson to use GPU. Below is what it should be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b60ea5-80e2-4aad-a549-7811176f2205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in trainloader:\n",
    "        y_pred = model(inputs.to(device))\n",
    "        loss = loss_fn(y_pred, labels.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    acc = 0\n",
    "    count = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            y_pred = model(inputs.to(device))\n",
    "            acc += (torch.argmax(y_pred, 1) == labels.to(device)).float().sum()\n",
    "            count += len(labels)\n",
    "    acc /= count\n",
    "    print(\"Epoch %d: model accuracy %.2f%%\" % (epoch, acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785c0f6-9c23-4927-a667-68944f3b60b1",
   "metadata": {},
   "source": [
    "The changes made are the following: You check if GPU is available and set the <code>device</code> accordingly. Then the model is sent to the device. When the input (i.e., a batch of images) is pass on to the model, it should be sent to the corresponding device first. Since the model output will also be there, the loss calculation or the accuracy calculation should also have the target sent to the GPU first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a5b29c-430e-4623-8cee-b666831196a3",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62987ac5-8a91-4ec0-bff1-85146bfbb951",
   "metadata": {},
   "source": [
    "Take a moment and look back at how far you have come.\n",
    "\n",
    "- You discovered PyTorch as a deep learning library in Python\n",
    "\n",
    "- You built your first neural network using PyTorch and learned how to do classification with a neural network\n",
    "\n",
    "- You learned key components in deep learning, including loss function, optimizer, training loop, and evaluation\n",
    "\n",
    "- Finally, you took the next step and learned about and developed convolutional neural networks for computer vision tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
